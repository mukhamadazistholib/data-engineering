{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-19\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Spark'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under yellow_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"yellow_tripdata_2021-02.parquet\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2021-02-01 07:40:47|  2021-02-01 07:48:28|            1.0|          2.3|       1.0|                 N|         141|         226|           2|        8.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        12.3|                 2.5|       null|\n",
      "|       1| 2021-02-01 07:07:44|  2021-02-01 07:20:31|            1.0|          1.6|       1.0|                 N|          43|         263|           2|        9.5|  3.0|    0.5|       0.0|         0.0|                  0.3|        13.3|                 0.0|       null|\n",
      "|       1| 2021-02-01 07:59:36|  2021-02-01 08:24:13|            1.0|          5.3|       1.0|                 N|         114|         263|           2|       19.0|  3.0|    0.5|       0.0|         0.0|                  0.3|        22.8|                 2.5|       null|\n",
      "|       2| 2021-02-01 07:03:26|  2021-02-01 07:16:32|            1.0|         2.79|       1.0|                 N|         236|         229|           1|       11.0|  0.5|    0.5|      2.96|         0.0|                  0.3|       17.76|                 2.5|       null|\n",
      "|       2| 2021-02-01 07:20:20|  2021-02-01 07:24:03|            2.0|         0.64|       1.0|                 N|         229|         140|           1|        4.5|  0.5|    0.5|      1.66|         0.0|                  0.3|        9.96|                 2.5|       null|\n",
      "|       2| 2021-02-01 07:55:03|  2021-02-01 08:03:39|            1.0|         1.97|       1.0|                 N|         238|          75|           1|        8.5|  0.5|    0.5|      1.96|         0.0|                  0.3|       11.76|                 0.0|       null|\n",
      "|       1| 2021-02-01 07:09:22|  2021-02-01 07:53:48|            1.0|         26.6|       1.0|                 N|         132|         200|           1|       69.0|  0.5|    0.5|       0.0|        6.12|                  0.3|       76.42|                 0.0|       null|\n",
      "|       2| 2021-02-01 07:52:15|  2021-02-01 08:16:24|            4.0|         6.07|       1.0|                 N|         249|         181|           1|       21.0|  0.5|    0.5|       6.2|         0.0|                  0.3|        31.0|                 2.5|       null|\n",
      "|       1| 2021-02-01 07:08:29|  2021-02-01 07:21:22|            1.0|          2.0|       1.0|                 N|          79|         246|           1|        9.0|  3.0|    0.5|       3.2|         0.0|                  0.3|        16.0|                 2.5|       null|\n",
      "|       1| 2021-02-01 07:28:13|  2021-02-01 07:31:40|            1.0|          0.8|       1.0|                 Y|          75|          74|           2|        5.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         6.3|                 0.0|       null|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\python\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = df \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')\n",
    "df.registerTempTable('data_table')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|taxi_trips_15feb|\n",
      "+----------------+\n",
      "|           43686|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_trips_15feb = spark.sql(\"\"\" \n",
    "    SELECT COUNT(pickup_datetime) AS taxi_trips_15feb\n",
    "    FROM data_table\n",
    "    WHERE pickup_datetime >= '2021-02-15 00:00:00' AND pickup_datetime < '2021-02-16 00:00:00'\n",
    "\"\"\")\n",
    "taxi_trips_15feb.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the longest trip for each day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|pickup_datetime|longest_trip|\n",
      "+---------------+------------+\n",
      "|     2021-02-16|   221188.25|\n",
      "|     2021-02-20|   188054.03|\n",
      "|     2021-02-08|   186617.92|\n",
      "|     2021-02-07|   186510.67|\n",
      "|     2021-02-03|   186079.73|\n",
      "|     2021-02-17|   140145.44|\n",
      "|     2021-02-14|   115928.92|\n",
      "|     2021-02-05|    91134.16|\n",
      "|     2021-02-26|    90796.21|\n",
      "|     2021-02-24|    90073.44|\n",
      "+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longest_trip = df.withColumn(\"pickup_datetime\" , to_date(df['pickup_datetime']))\\\n",
    "                      .select(['pickup_datetime','trip_distance'])\\\n",
    "                      .where(\"pickup_datetime >= '2021-02-01' \")\\\n",
    "                      .groupby(F.col('pickup_datetime')).agg(F.max('trip_distance').alias('longest_trip')).sort(desc(\"longest_trip\"))\n",
    "longest_trip.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Top 5 Most frequent _dispatching_base_num_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under fhv_tripdata_2021-02.parquet\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: double (nullable = true)\n",
      " |-- DOlocationID: double (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv = spark.read.parquet(\"fhv_tripdata_2021-02.parquet\", header=True, inferSchema=True)\n",
    "df_fhv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 07:01:00|2021-02-01 08:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 07:55:40|2021-02-01 08:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:14:03|2021-02-01 07:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:27:48|2021-02-01 07:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 07:12:50|2021-02-01 07:26:38|        null|       225.0|   null|                B00037|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fhv.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|dispatching_base_num|count|\n",
      "+--------------------+-----+\n",
      "|              B00856|35077|\n",
      "|              B01312|33089|\n",
      "|              B01145|31114|\n",
      "|              B02794|30397|\n",
      "|              B03016|29794|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_freq = df_fhv.groupBy(\"dispatching_base_num\").count() \\\n",
    "                    .orderBy(F.col('count').desc())\n",
    "most_freq.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Top 5 Most common location pairs (_PUlocationID_ and _DOlocationID_) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----+\n",
      "|PUlocationID|DOlocationID|count|\n",
      "+------------+------------+-----+\n",
      "|         237|         236|11455|\n",
      "|         236|         237| 9901|\n",
      "|         236|         236| 8819|\n",
      "|         237|         237| 7324|\n",
      "|         264|         264| 5732|\n",
      "|         239|         238| 4991|\n",
      "|         141|         236| 4756|\n",
      "|         239|         142| 4243|\n",
      "|         238|         239| 4199|\n",
      "|         236|         141| 4048|\n",
      "+------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_loc = df.where(\"PUlocationID IS NOT NULL AND DOlocationID IS NOT NULL\") \\\n",
    "                      .groupBy([\"PUlocationID\",'DOlocationID']) \\\n",
    "                      .count() \\\n",
    "                      .orderBy(F.col('count').desc())\n",
    "common_loc.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----+\n",
      "|PUlocationID|DOlocationID|count|\n",
      "+------------+------------+-----+\n",
      "|       206.0|       206.0| 2374|\n",
      "|       221.0|       206.0| 2112|\n",
      "|       129.0|       129.0| 1902|\n",
      "|         7.0|         7.0| 1829|\n",
      "|       179.0|       179.0| 1736|\n",
      "|       221.0|       221.0| 1562|\n",
      "|       223.0|       223.0| 1522|\n",
      "|        92.0|        92.0| 1383|\n",
      "|       206.0|       221.0| 1309|\n",
      "|        56.0|        56.0| 1073|\n",
      "+------------+------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_loc_fhv = df_fhv.where(\"PUlocationID IS NOT NULL AND DOlocationID IS NOT NULL\") \\\n",
    "                          .groupBy([\"PUlocationID\",'DOlocationID']) \\\n",
    "                          .count() \\\n",
    "                          .orderBy(F.col('count').desc())\n",
    "common_loc_fhv.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to BQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \".google/credentials/google_credentials.json\"\n",
    "gcs_bucket = 'playgrounddata-bucket'\n",
    "bq_dataset = 'taxi_trips'\n",
    "bq_table = 'yellow_tripdata_2021-02'\n",
    "\n",
    "df.write.format(\"bigquery\") \\\n",
    "  .option(\"table\",\"{}.{}\".format(bq_dataset, bq_table)) \\\n",
    "  .option(\"temporaryGcsBucket\", gcs_bucket) \\\n",
    "  .mode('overwrite') \\\n",
    "  .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
